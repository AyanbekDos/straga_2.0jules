import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import asyncio
import json
from sqlalchemy import select, func
from openai import AsyncOpenAI
from rich import print as rprint
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
from models.models import Chunk, Page, Link, DatasetSettings
from core.db import async_session_maker

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def run_qc(dataset_id: int):
    async with async_session_maker() as session:
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ DatasetSettings
        settings_result = await session.execute(
            select(DatasetSettings.gpt_model).where(DatasetSettings.dataset_id == dataset_id)
        )
        model = settings_result.scalar_one_or_none() or "gpt-3.5-turbo"

        # –ë–µ—Ä—ë–º 10 —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        result = await session.execute(
            select(Chunk)
            .join(Page, Page.id == Chunk.page_id)
            .join(Link, Link.id == Page.link_id)
            .where(Link.dataset_id == dataset_id)
            .order_by(func.random())
            .limit(10)
        )
        chunks = result.scalars().all()

        if not chunks:
            rprint("[bold red]‚ùå –ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.[/bold red]")
            return

        # –°–æ–±–∏—Ä–∞–µ–º JSON –¥–ª—è GPT
        gpt_input = []
        for chunk in chunks:
            sentences = chunk.chunk_text.split(". ")
            head = ". ".join(sentences[:3])
            tail = ". ".join(sentences[-3:])
            gpt_input.append({
                "chunk_id": chunk.id,
                "sample": f"–ù–∞—á–∞–ª–æ —á–∞–Ω–∫–∞ id={chunk.id}:\n{head}...\n...\n–ö–æ–Ω–µ—Ü —á–∞–Ω–∫–∞ id={chunk.id}:\n{tail}"
            })

        # –ü—Ä–æ–º–ø—Ç
        prompt = [
            {"role": "system", "content": "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä chunk-–º–∞—Å—Ç–µ—Ä—Å–∫–æ–π. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –ª–æ–≥–∏—á–Ω–æ –æ–±—Ä–µ–∑–∞–Ω—ã –∫—É—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –≤—ã–≥–ª—è–¥—è—Ç –æ–±—Ä—É–±–ª–µ–Ω–Ω—ã–º–∏, –ø–æ–º–µ—Ç—å –∫–∞–∫ bad. –í–µ—Ä–Ω–∏ JSON —Å–æ —Å–ø–∏—Å–∫–æ–º: [{chunk_id: ..., verdict: 'good' | 'bad'}]"},
            {"role": "user", "content": json.dumps(gpt_input, ensure_ascii=False)}
        ]

        # GPT –≤—ã–∑–æ–≤
        rprint(f"[bold magenta]ü§ñ –ú–æ–¥–µ–ª—å:[/bold magenta] {model}")
        response = await client.chat.completions.create(model=model, messages=prompt)
        reply = response.choices[0].message.content.strip()

        try:
            parsed = json.loads(reply)
        except Exception as e:
            rprint("[bold red]‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ –æ—Ç–≤–µ—Ç–∞ GPT:[/bold red]", e)
            print(reply)
            return

        bad_count = sum(1 for item in parsed if item["verdict"] == "bad")
        total = len(parsed)
        bad_ratio = bad_count / total

        rprint(f"\nüìã [bold cyan]–†–µ–∑—É–ª—å—Ç–∞—Ç—ã QC:[/bold cyan] {bad_count} –∏–∑ {total} ‚Äî bad ({bad_ratio:.0%})")

        if bad_ratio > 0.3:
            rprint("[bold red]‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–ª–æ—Ö–∏—Ö —á–∞–Ω–∫–æ–≤ ‚Äî —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞–∑–º–µ—Ä chunk_size –∏–ª–∏ chunk_overlap[/bold red]")

if __name__ == "__main__":
    asyncio.run(run_qc(int(sys.argv[1])))
